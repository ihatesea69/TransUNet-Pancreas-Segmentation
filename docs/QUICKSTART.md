# TransUNet Quick Start Guide

**5-Minute Setup for Pancreas Segmentation**

---

## ğŸš€ Installation (2 minutes)

```bash
# Clone and setup
git clone https://github.com/ihatesea69/TransUNet-Pancreas-Segmentation.git
cd TransUNet-Pancreas-Segmentation
uv sync && .venv\Scripts\activate
```

---

## ğŸ“š Run Notebooks (Interactive)

```bash
# Notebook 01: Download data & preprocessing (one-time)
jupyter notebook 01_Data_Exploration_and_Processing.ipynb

# Notebook 02: Explore TransUNet architecture
jupyter notebook 02_Model_Architecture.ipynb

# Notebook 03: Train model (requires GPU)
jupyter notebook 03_Training_Pipeline.ipynb

# Notebook 04: Evaluate & visualize results
jupyter notebook 04_Evaluation_and_Demo.ipynb
```

---

## âš¡ CLI Commands (Scripted)

```bash
# Training
python main.py train --variant small --epochs 50

# Inference
python main.py inference \
  --checkpoint checkpoints/model.pth \
  --input data/scan.nii.gz
```

---

## ğŸ Python API (Programmatic)

```python
from src.model import create_transunet
import torch

# Load model
model = create_transunet(variant="small")
checkpoint = torch.load("checkpoints/best_model.pth")
model.load_state_dict(checkpoint["model_state_dict"])

# Inference
with torch.no_grad():
    output = model(input_slice)
    prediction = torch.argmax(output, dim=1)
```

---

## ğŸ“Š Project Structure

```
TransUNet-Pancreas-Segmentation/
â”œâ”€â”€ ğŸ““ 01_Data_*.ipynb       â† Start here
â”œâ”€â”€ ğŸ““ 02_Model_*.ipynb      â† Architecture
â”œâ”€â”€ ğŸ““ 03_Training_*.ipynb   â† Train
â”œâ”€â”€ ğŸ““ 04_Evaluation_*.ipynb â† Evaluate
â”œâ”€â”€ ğŸ“¦ src/                  â† Core code
â”œâ”€â”€ ğŸ’¾ checkpoints/          â† Model weights
â””â”€â”€ ğŸ“Š outputs/              â† Results
```

---

## âš™ï¸ Model Variants

| Variant | VRAM | Parameters | Speed |
|---------|------|-----------|-------|
| small   | 4GB  | 17M       | Fast  |
| base    | 12GB | 105M      | Medium|
| large   | 24GB | 300M      | Slow  |

---

## ğŸ”§ Common Issues

**Dataset download fails?**
```python
# In notebook 01, manually set:
DATASET_URL = "https://msd-for-monai.s3-us-west-2.amazonaws.com/Task07_Pancreas.tar"
```

**CUDA out of memory?**
```python
# Reduce batch size in notebook 03:
CONFIG["batch_size"] = 4  # or 2
```

**Windows num_workers error?**
```python
# Set num_workers to 0:
CONFIG["num_workers"] = 0
```

---

## ğŸ“– Learn More

- [Full Documentation](README.md)
- [Architecture Details](02_Model_Architecture.ipynb)
- [Original Paper](https://arxiv.org/abs/2102.04306)
- [Dataset Info](http://medicaldecathlon.com/)

---

## ğŸ†˜ Support

- [Open an Issue](https://github.com/ihatesea69/TransUNet-Pancreas-Segmentation/issues)
- [Discussions](https://github.com/ihatesea69/TransUNet-Pancreas-Segmentation/discussions)
