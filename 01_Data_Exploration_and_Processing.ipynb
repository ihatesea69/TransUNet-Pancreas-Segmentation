{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 01: Data Exploration and Processing\n",
        "\n",
        "## Pancreas CT Segmentation using TransUNet\n",
        "\n",
        "This notebook covers:\n",
        "1. Environment setup and library installation\n",
        "2. Downloading MSD Task07 Pancreas dataset\n",
        "3. Data splitting (Train/Val/Test)\n",
        "4. MONAI transformation pipeline\n",
        "5. Visualization utilities\n",
        "6. Sanity check with sample data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MONAI version: 1.5.1\n",
            "Numpy version: 2.4.1\n",
            "Pytorch version: 2.10.0+cpu\n",
            "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
            "MONAI rev id: 9c6d819f97e37f36c72f3bdfad676b455bd2fa0d\n",
            "MONAI __file__: c:\\Users\\<username>\\Desktop\\Đồ Án Tốt Nghiệp\\.venv\\Lib\\site-packages\\monai\\__init__.py\n",
            "\n",
            "Optional dependencies:\n",
            "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "Nibabel version: 5.3.3\n",
            "scikit-image version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "scipy version: 1.17.0\n",
            "Pillow version: 12.1.0\n",
            "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "TorchVision version: 0.25.0+cpu\n",
            "tqdm version: 4.67.1\n",
            "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "psutil version: 7.2.1\n",
            "pandas version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "einops version: 0.8.1\n",
            "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "\n",
            "For details about installing the optional dependencies, please visit:\n",
            "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import standard libraries\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "# Scientific computing\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Medical imaging\n",
        "import nibabel as nib\n",
        "from tqdm import tqdm\n",
        "\n",
        "# MONAI for medical image processing\n",
        "import monai\n",
        "from monai.apps import download_and_extract\n",
        "from monai.config import print_config\n",
        "from monai.data import Dataset, DataLoader\n",
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    LoadImaged,\n",
        "    EnsureChannelFirstd,\n",
        "    Orientationd,\n",
        "    Spacingd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        "    EnsureTyped,\n",
        ")\n",
        "\n",
        "# Print MONAI configuration\n",
        "print_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: c:\\Users\\LENOVO\\Desktop\\Đồ Án Tốt Nghiệp\n",
            "Data directory: c:\\Users\\LENOVO\\Desktop\\Đồ Án Tốt Nghiệp\\data\n",
            "Output directory: c:\\Users\\LENOVO\\Desktop\\Đồ Án Tốt Nghiệp\\outputs\n"
          ]
        }
      ],
      "source": [
        "# Set random seeds for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Project paths\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "DATA_DIR = PROJECT_ROOT / \"data\"\n",
        "OUTPUT_DIR = PROJECT_ROOT / \"outputs\"\n",
        "\n",
        "# Create directories\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n",
        "print(f\"Data directory: {DATA_DIR}\")\n",
        "print(f\"Output directory: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Download MSD Task07 Pancreas Dataset\n",
        "\n",
        "The Medical Segmentation Decathlon (MSD) Task07 Pancreas dataset contains:\n",
        "- 420 portal venous phase CT scans\n",
        "- Labels for pancreas and pancreatic tumors\n",
        "- Source: Memorial Sloan Kettering Cancer Center"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading MSD Task07 Pancreas dataset...\n",
            "This may take a while (~3GB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Task07_Pancreas.tar:   4%|▍         | 475M/11.4G [03:58<1:07:24, 2.92MB/s]   "
          ]
        }
      ],
      "source": [
        "# MSD Task07 Pancreas URL\n",
        "DATASET_URL = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task07_Pancreas.tar\"\n",
        "DATASET_DIR = DATA_DIR / \"Task07_Pancreas\"\n",
        "\n",
        "# Download and extract if not already present\n",
        "if not DATASET_DIR.exists():\n",
        "    print(\"Downloading MSD Task07 Pancreas dataset...\")\n",
        "    print(\"This may take a while (~3GB)\")\n",
        "    \n",
        "    download_and_extract(\n",
        "        url=DATASET_URL,\n",
        "        filepath=str(DATA_DIR / \"Task07_Pancreas.tar\"),\n",
        "        output_dir=str(DATA_DIR),\n",
        "    )\n",
        "    print(\"Download complete!\")\n",
        "else:\n",
        "    print(f\"Dataset already exists at: {DATASET_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explore dataset structure\n",
        "print(\"Dataset structure:\")\n",
        "for item in DATASET_DIR.iterdir():\n",
        "    if item.is_dir():\n",
        "        files = list(item.glob(\"*\"))\n",
        "        print(f\"  {item.name}/: {len(files)} files\")\n",
        "    else:\n",
        "        print(f\"  {item.name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset.json for metadata\n",
        "dataset_json_path = DATASET_DIR / \"dataset.json\"\n",
        "\n",
        "with open(dataset_json_path, \"r\") as f:\n",
        "    dataset_info = json.load(f)\n",
        "\n",
        "print(\"Dataset Information:\")\n",
        "print(f\"  Name: {dataset_info.get('name', 'N/A')}\")\n",
        "print(f\"  Description: {dataset_info.get('description', 'N/A')}\")\n",
        "print(f\"  Modality: {dataset_info.get('modality', 'N/A')}\")\n",
        "print(f\"  Labels: {dataset_info.get('labels', 'N/A')}\")\n",
        "print(f\"  Number of training samples: {dataset_info.get('numTraining', 'N/A')}\")\n",
        "print(f\"  Number of test samples: {dataset_info.get('numTest', 'N/A')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Splitting\n",
        "\n",
        "Split the training data into:\n",
        "- Train: 80%\n",
        "- Validation: 10%\n",
        "- Test: 10%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_data_splits(dataset_dir, train_ratio=0.8, val_ratio=0.1, seed=42):\n",
        "    \"\"\"\n",
        "    Split dataset into train, validation, and test sets.\n",
        "    \n",
        "    Args:\n",
        "        dataset_dir: Path to Task07_Pancreas directory\n",
        "        train_ratio: Proportion for training (default: 0.8)\n",
        "        val_ratio: Proportion for validation (default: 0.1)\n",
        "        seed: Random seed for reproducibility\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary with train, val, test lists\n",
        "    \"\"\"\n",
        "    dataset_dir = Path(dataset_dir)\n",
        "    \n",
        "    # Get all training images\n",
        "    images_dir = dataset_dir / \"imagesTr\"\n",
        "    labels_dir = dataset_dir / \"labelsTr\"\n",
        "    \n",
        "    image_files = sorted(images_dir.glob(\"*.nii.gz\"))\n",
        "    \n",
        "    # Create data dictionaries\n",
        "    data_dicts = []\n",
        "    for img_path in image_files:\n",
        "        # Label filename: pancreas_XXX.nii.gz (image is pancreas_XXX_0000.nii.gz)\n",
        "        label_name = img_path.name.replace(\"_0000\", \"\")\n",
        "        label_path = labels_dir / label_name\n",
        "        \n",
        "        if label_path.exists():\n",
        "            data_dicts.append({\n",
        "                \"image\": str(img_path),\n",
        "                \"label\": str(label_path),\n",
        "            })\n",
        "    \n",
        "    print(f\"Total samples with labels: {len(data_dicts)}\")\n",
        "    \n",
        "    # Shuffle and split\n",
        "    random.seed(seed)\n",
        "    random.shuffle(data_dicts)\n",
        "    \n",
        "    n_total = len(data_dicts)\n",
        "    n_train = int(n_total * train_ratio)\n",
        "    n_val = int(n_total * val_ratio)\n",
        "    \n",
        "    train_data = data_dicts[:n_train]\n",
        "    val_data = data_dicts[n_train:n_train + n_val]\n",
        "    test_data = data_dicts[n_train + n_val:]\n",
        "    \n",
        "    splits = {\n",
        "        \"train\": train_data,\n",
        "        \"val\": val_data,\n",
        "        \"test\": test_data,\n",
        "    }\n",
        "    \n",
        "    print(f\"Train: {len(train_data)} samples\")\n",
        "    print(f\"Val: {len(val_data)} samples\")\n",
        "    print(f\"Test: {len(test_data)} samples\")\n",
        "    \n",
        "    return splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create splits\n",
        "data_splits = create_data_splits(DATASET_DIR, seed=SEED)\n",
        "\n",
        "# Save splits to JSON\n",
        "splits_path = OUTPUT_DIR / \"data_splits.json\"\n",
        "with open(splits_path, \"w\") as f:\n",
        "    json.dump(data_splits, f, indent=2)\n",
        "\n",
        "print(f\"\\nData splits saved to: {splits_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. MONAI Transformation Pipeline\n",
        "\n",
        "Define preprocessing transforms:\n",
        "1. LoadImage: Load NIfTI files\n",
        "2. EnsureChannelFirst: Add channel dimension\n",
        "3. Orientation (RAS): Standardize orientation\n",
        "4. Spacing: Resample to 1.0mm isotropic\n",
        "5. ScaleIntensityRanged: HU windowing [-175, 250]\n",
        "6. CropForeground: Remove empty background"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define preprocessing transforms\n",
        "preprocessing_transforms = Compose([\n",
        "    LoadImaged(keys=[\"image\", \"label\"]),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "    Spacingd(\n",
        "        keys=[\"image\", \"label\"],\n",
        "        pixdim=(1.0, 1.0, 1.0),\n",
        "        mode=(\"bilinear\", \"nearest\"),\n",
        "    ),\n",
        "    ScaleIntensityRanged(\n",
        "        keys=[\"image\"],\n",
        "        a_min=-175,  # HU minimum (soft tissue window)\n",
        "        a_max=250,   # HU maximum\n",
        "        b_min=0.0,\n",
        "        b_max=1.0,\n",
        "        clip=True,\n",
        "    ),\n",
        "    CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
        "    EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "])\n",
        "\n",
        "print(\"Preprocessing pipeline defined:\")\n",
        "for i, t in enumerate(preprocessing_transforms.transforms):\n",
        "    print(f\"  {i+1}. {t.__class__.__name__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualization Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_slices(image, label=None, title=\"CT Slices\", figsize=(15, 5)):\n",
        "    \"\"\"\n",
        "    Display axial, coronal, and sagittal slices of a 3D volume.\n",
        "    \n",
        "    Args:\n",
        "        image: 3D numpy array (D, H, W) or (C, D, H, W)\n",
        "        label: Optional 3D numpy array with same shape\n",
        "        title: Figure title\n",
        "        figsize: Figure size\n",
        "    \"\"\"\n",
        "    # Handle channel dimension\n",
        "    if image.ndim == 4:\n",
        "        image = image[0]\n",
        "    if label is not None and label.ndim == 4:\n",
        "        label = label[0]\n",
        "    \n",
        "    # Convert to numpy if tensor\n",
        "    if hasattr(image, 'numpy'):\n",
        "        image = image.numpy()\n",
        "    if label is not None and hasattr(label, 'numpy'):\n",
        "        label = label.numpy()\n",
        "    \n",
        "    # Get center slices\n",
        "    d, h, w = image.shape\n",
        "    axial_idx = d // 2\n",
        "    coronal_idx = h // 2\n",
        "    sagittal_idx = w // 2\n",
        "    \n",
        "    # Find slice with maximum pancreas area for better visualization\n",
        "    if label is not None:\n",
        "        pancreas_area_per_slice = np.sum(label > 0, axis=(1, 2))\n",
        "        if pancreas_area_per_slice.max() > 0:\n",
        "            axial_idx = np.argmax(pancreas_area_per_slice)\n",
        "    \n",
        "    # Create figure\n",
        "    fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
        "    \n",
        "    # Axial slice (top-down view)\n",
        "    axes[0].imshow(image[axial_idx, :, :], cmap=\"gray\")\n",
        "    if label is not None:\n",
        "        mask = np.ma.masked_where(label[axial_idx, :, :] == 0, label[axial_idx, :, :])\n",
        "        axes[0].imshow(mask, cmap=\"jet\", alpha=0.5, vmin=0, vmax=2)\n",
        "    axes[0].set_title(f\"Axial (slice {axial_idx}/{d})\")\n",
        "    axes[0].axis(\"off\")\n",
        "    \n",
        "    # Coronal slice (front view)\n",
        "    axes[1].imshow(image[:, coronal_idx, :], cmap=\"gray\", aspect='auto')\n",
        "    if label is not None:\n",
        "        mask = np.ma.masked_where(label[:, coronal_idx, :] == 0, label[:, coronal_idx, :])\n",
        "        axes[1].imshow(mask, cmap=\"jet\", alpha=0.5, vmin=0, vmax=2, aspect='auto')\n",
        "    axes[1].set_title(f\"Coronal (slice {coronal_idx}/{h})\")\n",
        "    axes[1].axis(\"off\")\n",
        "    \n",
        "    # Sagittal slice (side view)\n",
        "    axes[2].imshow(image[:, :, sagittal_idx], cmap=\"gray\", aspect='auto')\n",
        "    if label is not None:\n",
        "        mask = np.ma.masked_where(label[:, :, sagittal_idx] == 0, label[:, :, sagittal_idx])\n",
        "        axes[2].imshow(mask, cmap=\"jet\", alpha=0.5, vmin=0, vmax=2, aspect='auto')\n",
        "    axes[2].set_title(f\"Sagittal (slice {sagittal_idx}/{w})\")\n",
        "    axes[2].axis(\"off\")\n",
        "    \n",
        "    plt.suptitle(title, fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_volume(image, label):\n",
        "    \"\"\"\n",
        "    Analyze volume statistics.\n",
        "    \n",
        "    Args:\n",
        "        image: Image volume\n",
        "        label: Label volume\n",
        "    \"\"\"\n",
        "    # Handle channel dimension\n",
        "    if image.ndim == 4:\n",
        "        image = image[0]\n",
        "    if label.ndim == 4:\n",
        "        label = label[0]\n",
        "    \n",
        "    # Convert to numpy\n",
        "    if hasattr(image, 'numpy'):\n",
        "        image = image.numpy()\n",
        "    if hasattr(label, 'numpy'):\n",
        "        label = label.numpy()\n",
        "    \n",
        "    print(\"Volume Statistics:\")\n",
        "    print(f\"  Image shape: {image.shape}\")\n",
        "    print(f\"  Image dtype: {image.dtype}\")\n",
        "    print(f\"  Image range: [{image.min():.3f}, {image.max():.3f}]\")\n",
        "    print(f\"  Image mean: {image.mean():.3f}\")\n",
        "    print(f\"  Image std: {image.std():.3f}\")\n",
        "    \n",
        "    print(f\"\\n  Label shape: {label.shape}\")\n",
        "    print(f\"  Label unique values: {np.unique(label)}\")\n",
        "    \n",
        "    # Calculate class distribution\n",
        "    total_voxels = label.size\n",
        "    for cls in np.unique(label):\n",
        "        count = np.sum(label == cls)\n",
        "        percentage = 100 * count / total_voxels\n",
        "        print(f\"  Class {int(cls)}: {count:,} voxels ({percentage:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Sanity Check: Load and Visualize Sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load one sample from training set\n",
        "sample_data = data_splits[\"train\"][0]\n",
        "print(f\"Loading sample:\")\n",
        "print(f\"  Image: {sample_data['image']}\")\n",
        "print(f\"  Label: {sample_data['label']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load raw volume (before preprocessing)\n",
        "raw_image = nib.load(sample_data[\"image\"])\n",
        "raw_label = nib.load(sample_data[\"label\"])\n",
        "\n",
        "print(\"Raw Volume Info:\")\n",
        "print(f\"  Image shape: {raw_image.shape}\")\n",
        "print(f\"  Image voxel size: {raw_image.header.get_zooms()}\")\n",
        "print(f\"  Image affine:\\n{raw_image.affine}\")\n",
        "\n",
        "# Show raw slices\n",
        "show_slices(\n",
        "    raw_image.get_fdata().transpose(2, 0, 1),  # Reorder to (D, H, W)\n",
        "    raw_label.get_fdata().transpose(2, 0, 1),\n",
        "    title=\"Raw CT Volume (Before Preprocessing)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply preprocessing transforms\n",
        "print(\"Applying preprocessing transforms...\")\n",
        "processed_data = preprocessing_transforms(sample_data)\n",
        "\n",
        "processed_image = processed_data[\"image\"]\n",
        "processed_label = processed_data[\"label\"]\n",
        "\n",
        "print(\"\\nProcessed Volume:\")\n",
        "analyze_volume(processed_image, processed_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize preprocessed volume\n",
        "show_slices(\n",
        "    processed_image,\n",
        "    processed_label,\n",
        "    title=\"Preprocessed CT Volume (After MONAI Pipeline)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show multiple axial slices with pancreas\n",
        "def show_pancreas_slices(image, label, num_slices=6, figsize=(18, 6)):\n",
        "    \"\"\"\n",
        "    Show multiple axial slices containing pancreas.\n",
        "    \"\"\"\n",
        "    if image.ndim == 4:\n",
        "        image = image[0]\n",
        "    if label.ndim == 4:\n",
        "        label = label[0]\n",
        "    \n",
        "    if hasattr(image, 'numpy'):\n",
        "        image = image.numpy()\n",
        "    if hasattr(label, 'numpy'):\n",
        "        label = label.numpy()\n",
        "    \n",
        "    # Find slices with pancreas\n",
        "    pancreas_slices = np.where(np.sum(label > 0, axis=(1, 2)) > 0)[0]\n",
        "    \n",
        "    if len(pancreas_slices) == 0:\n",
        "        print(\"No pancreas slices found!\")\n",
        "        return\n",
        "    \n",
        "    # Select evenly spaced slices\n",
        "    indices = np.linspace(0, len(pancreas_slices) - 1, num_slices, dtype=int)\n",
        "    selected_slices = pancreas_slices[indices]\n",
        "    \n",
        "    fig, axes = plt.subplots(2, num_slices, figsize=figsize)\n",
        "    \n",
        "    for i, slice_idx in enumerate(selected_slices):\n",
        "        # Top row: CT image\n",
        "        axes[0, i].imshow(image[slice_idx], cmap=\"gray\")\n",
        "        axes[0, i].set_title(f\"Slice {slice_idx}\")\n",
        "        axes[0, i].axis(\"off\")\n",
        "        \n",
        "        # Bottom row: CT with mask overlay\n",
        "        axes[1, i].imshow(image[slice_idx], cmap=\"gray\")\n",
        "        mask = np.ma.masked_where(label[slice_idx] == 0, label[slice_idx])\n",
        "        axes[1, i].imshow(mask, cmap=\"jet\", alpha=0.5, vmin=0, vmax=2)\n",
        "        axes[1, i].axis(\"off\")\n",
        "    \n",
        "    axes[0, 0].set_ylabel(\"CT Image\", fontsize=12)\n",
        "    axes[1, 0].set_ylabel(\"With Mask\", fontsize=12)\n",
        "    \n",
        "    plt.suptitle(\"Axial Slices with Pancreas Segmentation\", fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"Total slices with pancreas: {len(pancreas_slices)} / {image.shape[0]}\")\n",
        "\n",
        "show_pancreas_slices(processed_image, processed_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Dataset Statistics Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze a subset of volumes to get statistics\n",
        "def compute_dataset_statistics(data_list, transforms, num_samples=10):\n",
        "    \"\"\"\n",
        "    Compute statistics across multiple volumes.\n",
        "    \"\"\"\n",
        "    stats = {\n",
        "        \"shapes\": [],\n",
        "        \"pancreas_volumes\": [],\n",
        "        \"tumor_volumes\": [],\n",
        "        \"pancreas_slice_counts\": [],\n",
        "    }\n",
        "    \n",
        "    num_samples = min(num_samples, len(data_list))\n",
        "    \n",
        "    for i in tqdm(range(num_samples), desc=\"Analyzing volumes\"):\n",
        "        data = transforms(data_list[i])\n",
        "        image = data[\"image\"].numpy() if hasattr(data[\"image\"], 'numpy') else data[\"image\"]\n",
        "        label = data[\"label\"].numpy() if hasattr(data[\"label\"], 'numpy') else data[\"label\"]\n",
        "        \n",
        "        if image.ndim == 4:\n",
        "            image = image[0]\n",
        "        if label.ndim == 4:\n",
        "            label = label[0]\n",
        "        \n",
        "        stats[\"shapes\"].append(image.shape)\n",
        "        stats[\"pancreas_volumes\"].append(np.sum(label == 1))\n",
        "        stats[\"tumor_volumes\"].append(np.sum(label == 2))\n",
        "        stats[\"pancreas_slice_counts\"].append(np.sum(np.any(label > 0, axis=(1, 2))))\n",
        "    \n",
        "    return stats\n",
        "\n",
        "# Compute statistics\n",
        "print(\"Computing dataset statistics...\")\n",
        "dataset_stats = compute_dataset_statistics(\n",
        "    data_splits[\"train\"][:10],\n",
        "    preprocessing_transforms\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print statistics\n",
        "print(\"\\nDataset Statistics (10 samples):\")\n",
        "print(f\"\\nVolume shapes:\")\n",
        "for i, shape in enumerate(dataset_stats[\"shapes\"]):\n",
        "    print(f\"  Sample {i+1}: {shape}\")\n",
        "\n",
        "print(f\"\\nPancreas volume (voxels):\")\n",
        "print(f\"  Mean: {np.mean(dataset_stats['pancreas_volumes']):,.0f}\")\n",
        "print(f\"  Std: {np.std(dataset_stats['pancreas_volumes']):,.0f}\")\n",
        "print(f\"  Min: {np.min(dataset_stats['pancreas_volumes']):,.0f}\")\n",
        "print(f\"  Max: {np.max(dataset_stats['pancreas_volumes']):,.0f}\")\n",
        "\n",
        "print(f\"\\nSlices with pancreas:\")\n",
        "print(f\"  Mean: {np.mean(dataset_stats['pancreas_slice_counts']):.1f}\")\n",
        "print(f\"  Range: [{np.min(dataset_stats['pancreas_slice_counts'])}, {np.max(dataset_stats['pancreas_slice_counts'])}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook completed the following:\n",
        "\n",
        "1. **Environment Setup**: Imported all necessary libraries (MONAI, nibabel, matplotlib)\n",
        "2. **Data Download**: Downloaded MSD Task07 Pancreas dataset (~3GB)\n",
        "3. **Data Splitting**: Created 80/10/10 train/val/test splits saved to `outputs/data_splits.json`\n",
        "4. **Transform Pipeline**: Defined MONAI preprocessing with:\n",
        "   - Orientation standardization (RAS)\n",
        "   - Isotropic resampling (1.0mm)\n",
        "   - HU windowing [-175, 250]\n",
        "   - Foreground cropping\n",
        "5. **Visualization**: Created helper function to display 3-view slices with mask overlay\n",
        "6. **Sanity Check**: Verified preprocessing on sample volume\n",
        "\n",
        "Next: Notebook 02 - Model Architecture (TransUNet)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
